# Face Recognition & Face Locking System (Windows)

A **real-time face recognition and face locking system** that runs on **Windows + Python 3.12**.

Pipeline: **Camera â†’ Haar detection â†’ FaceMesh 5-point landmarks â†’ Face alignment (112Ã—112) â†’ ArcFace embedding**

Key capabilities:
- Detect and recognize multiple faces simultaneously
- **Lock onto a specific target face** with identity-based tracking + spatial fallback
- Detect actions on the locked face (head movement, smile)
- Log all events to a `.jsonl` history file
- Control a **servo motor** via **MQTT over ESP8266** â€” the servo tracks the locked face's horizontal position

---

## ğŸ“ Project Structure

```
Facelocking2/
â”‚
â”œâ”€â”€ .venv/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ face_db.npz          # Enrolled face embeddings
â”‚   â”‚   â””â”€â”€ face_db.json         # DB metadata
â”‚   â”œâ”€â”€ enroll/                  # Saved crop images per person
â”‚   â””â”€â”€ history/
â”‚       â””â”€â”€ history_log.jsonl    # Action event log (JSONL)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ embedder_arcface.onnx    # ArcFace ONNX model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ detect.py                # Main detection + face locking loop
â”‚   â”œâ”€â”€ enroll.py                # Face enrollment tool
â”‚   â”œâ”€â”€ faceLockServo.py         # Face locking + MQTT servo control
â”‚   â”œâ”€â”€ face_locking_controller.py
â”‚   â”œâ”€â”€ face_tracker.py
â”‚   â”œâ”€â”€ haar_5pt.py              # Haar + MediaPipe FaceMesh detector
â”‚   â”œâ”€â”€ align.py                 # 5-point face alignment
â”‚   â”œâ”€â”€ embed.py                 # ArcFace ONNX embedder
â”‚   â”œâ”€â”€ recognize.py             # DB matching / recognition helpers
â”‚   â”œâ”€â”€ action_detector.py       # Head movement & smile detection
â”‚   â”œâ”€â”€ history_manager.py       # JSONL event logger
â”‚   â”œâ”€â”€ history_logger.py
â”‚   â”œâ”€â”€ actions.py
â”‚   â”œâ”€â”€ landmarks.py
â”‚   â”œâ”€â”€ camera.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ servo_controller/
â”‚       â””â”€â”€ servo_controller.ino # ESP8266 Arduino sketch
â”‚
â”œâ”€â”€ init_project.py
â””â”€â”€ README.md
```

---

## ğŸ Python Version

```
Python 3.12.4
```

---

## ğŸ”§ Setup (Windows)

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install opencv-python numpy onnxruntime mediapipe insightface paho-mqtt
```

### MediaPipe version fix

```powershell
pip uninstall mediapipe -y
pip install mediapipe==0.10.9
```

---

## ğŸ§  ArcFace Model

Copy the model from the InsightFace buffalo pack:

```powershell
Copy-Item buffalo_l\w600k_r50.onnx models\embedder_arcface.onnx
```

---

## ğŸ‘¤ Step 1 â€” Enroll a Face

```powershell
python -m src.enroll
```

**Controls during enrollment:**

| Key | Action |
|-----|--------|
| `SPACE` | Capture one sample |
| `a` | Toggle auto-capture (every 0.25 s) |
| `s` | Save all samples to DB |
| `r` | Reset new samples (keep existing) |
| `q` | Quit |

- Needs **15 samples** by default (`EnrollConfig.samples_needed`)
- Saves aligned 112Ã—112 crops to `data/enroll/<name>/`
- Stores the mean ArcFace embedding in `data/db/face_db.npz`

---

## â–¶ï¸ Step 2 â€” Run Face Locking (detect.py)

```powershell
python -m src.detect
```

What this does:
1. Opens the camera (tries indices 0 â†’ 1 â†’ 2)
2. Detects all faces each frame using `HaarFaceMesh5pt`
3. Embeds and matches every face against the DB (`dist_thresh=0.34`)
4. **Locks onto "Kheira"** (hardcoded target â€” change `r["name"] == "Kheira"` in `detect.py` to your enrolled name)
5. Tracks the locked face with identity matching + spatial fallback (â‰¤ 50 px keypoint distance)
6. Releases lock after **2 seconds** of not seeing the target
7. Runs `ActionDetector` on the locked face â€” detects head movement (left/right/up/down) and smile
8. Logs all events via `HistoryManager` â†’ `data/history/history_log.jsonl`

**Color coding:**

| Color | Meaning |
|-------|---------|
| ğŸŸ¡ Yellow | Locked target face |
| ğŸŸ¢ Green | Recognised other face |
| ğŸ”´ Red | Unknown face |

Press `q` to quit.

---

## ğŸ¯ Step 3 (Optional) â€” Run with Servo Control (faceLockServo.py)

```powershell
python src/faceLockServo.py
```

- Prompts you to choose a target identity from the enrolled DB
- Locks face and publishes **servo angles (0â€“180Â°)** to MQTT topic `TeAmSiX/facelocking/servo_ctrl_x9z`
- MQTT Broker: `157.173.101.159:1883`
- Uses **MediaPipe FaceMesh** (full 468 landmarks) for detection in this mode
- Servo angle is smoothed and rate-limited (deadzone: 5Â°, interval: 100 ms)

---

## ğŸ¤– ESP8266 Servo Controller

File: `src/servo_controller/servo_controller.ino`

- Connects to WiFi: `Main Hall`
- Subscribes to MQTT topic: `TeAmSiX/facelocking/servo_ctrl_x9z`
- Servo on pin `D1`, range 0â€“180Â°
- **Search mode**: if no MQTT message arrives for **1500 ms**, the servo sweeps back and forth automatically
- Smooth movement: increments target angle by 1Â° per `loop()` tick (15 ms delay)

**Dependencies (Arduino Library Manager):**
- `ESP8266WiFi`
- `PubSubClient`
- `Servo`

---

## ğŸ“ Action Detection

`ActionDetector` runs on the locked face every frame using the 5-point keypoints `[left_eye, right_eye, nose, left_mouth, right_mouth]`:

| Action | Detection method |
|--------|-----------------|
| `moved left/right/up/down` | Bounding box centre displacement > 15 px |
| `smile` | Mouth width / face width ratio crosses 0.40 threshold |

Events are written immediately to `data/history/history_log.jsonl` (JSONL format).

---

## â— Common Errors

**`ModuleNotFoundError`**
- Make sure `src/__init__.py` exists
- Always run with `python -m src.detect` (not `python src/detect.py`)

**MediaPipe import error**
```powershell
pip install mediapipe==0.10.9
```

**`Failed to open camera`**
- `enroll.py` and `detect.py` try camera indices 0, 1, 2 automatically
- Make sure no other application is using the camera

**MQTT connection timeout**
- Check that the broker at `157.173.101.159:1883` is reachable from your network
- `faceLockServo.py` will still run in offline mode (servo commands will not be sent)

---

## ğŸ”’ Changing the Lock Target

In `src/detect.py`, line 92:
```python
candidates = [r for r in recognized_faces if r["accepted"] and r["name"] == "Albert"]
```
Replace `"Albert"` with any name you have enrolled.

---

## ğŸš€ Possible Extensions

- FAISS approximate nearest-neighbour search for large DBs
- Full blink detection (requires 68-point or FaceMesh EAR landmarks)
- GUI dashboard
- Multi-target locking
- Cloud/database event logging
